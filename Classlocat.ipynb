{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMeIvjUKJNfpdtlcjS8dMzX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbouCamara/COURS-IA/blob/main/Classlocat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InC-KT82EKI8"
      },
      "source": [
        "# This will import the python's module os\n",
        "import os\n",
        "from scipy import io\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# imgaug: load and save images\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "import re\n",
        "def extract_mat_contents(annot_directory, image_dir):\n",
        "\t        # Create MAT Parser\n",
        "\t        mat = scipy.io.loadmat(annot_directory)\n",
        "\t        # Get the height and width for our image\n",
        "\t        height, width = cv2.imread(image_dir).shape[:2]\n",
        "\t        # Get the bounding box co-ordinates\n",
        "\t        x1, y2, y1, x2 = tuple(map(tuple, mat['box_coord']))[0]\n",
        "\t        # We Split the image Directory passed in the method and choose the index\n",
        "\t        # Of the Folders name which is the same as it's class\n",
        "\t        class_name = image_dir.split('/')[2]\n",
        "\t        filename = '/'.join(image_dir.split('/')[-2:])\n",
        "\t        # Return the extracted attributes\n",
        "\t        return filename,  width, height, class_name, x1,y1,x2,y2"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAxMUDowOWK9"
      },
      "source": [
        "# Function to convert MAT files to CSV\n",
        "def mat_to_csv(annot_directory, image_directory, classes_folders):\n",
        "\n",
        "  # List containing all our attributes regarding each image\n",
        "  mat_list = []\n",
        "\n",
        "  # We loop our each class and its labels one by one to preprocess and augment \n",
        "  for class_folder in classes_folders:\n",
        "\n",
        "    # Set our images and annotations directory\n",
        "    image_dir = os.path.join(image_directory, class_folder)\n",
        "    annot_dir = os.path.join(annot_directory, class_folder) \n",
        "\n",
        "    # Get each file in the image and annotation directory\n",
        "    mat_files = sorted(os.listdir(annot_dir))\n",
        "    img_files = sorted(os.listdir(image_dir))\n",
        "\n",
        "    # Loop over each of the image and its label\n",
        "    for mat, image_file in zip(mat_files, img_files):\n",
        "      \n",
        "      # Full mat path\n",
        "      mat_path = os.path.join(annot_dir, mat)\n",
        "\n",
        "      # Full path Image\n",
        "      img_path = os.path.join(image_dir, image_file)\n",
        "\n",
        "      # Get Attributes for each image \n",
        "      value = extract_mat_contents(mat_path, img_path)\n",
        "\n",
        "      # Append the attributes to the mat_list\n",
        "      mat_list.append(value)\n",
        "\n",
        "  # Columns for Pandas DataFrame\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', \n",
        "                 'xmax', 'ymax']\n",
        "\n",
        "  # Create the DataFrame from mat_list\n",
        "  mat_df = pd.DataFrame(mat_list, columns=column_name)\n",
        "\n",
        "  # Return the dataframe\n",
        "  return mat_df\n",
        "\n",
        "# The Classes we will use for our training\n",
        "classes_list = sorted(['butterfly',  'cougar_face', 'elephant'])\n",
        "\n",
        "\n",
        "# Set our images and annotations directory\n",
        "image_directory = 'CALTECH/CALTECH_Dataset'\n",
        "annot_directory = 'CALTECH/CALTECH_Annotations'\n",
        "\n",
        "# Run the function to convert all the MAT files to a Pandas DataFrame\n",
        "labels_df = mat_to_csv(annot_directory, image_directory, classes_list)\n",
        "\n",
        "# Saving the Pandas DataFrame as CSV File\n",
        "labels_df.to_csv(('labels.csv'), index=None)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyaFbyat8ZfH"
      },
      "source": [
        "# Function to convert bounding box image into DataFrame \n",
        "def bounding_boxes_to_df(bounding_boxes_object):\n",
        "\n",
        "    # Convert Bounding Boxes Object to Array\n",
        "    bounding_boxes_array = bounding_boxes_object.to_xyxy_array()\n",
        "    \n",
        "    # Convert the array into DataFrame\n",
        "    df_bounding_boxes = pd.DataFrame(bounding_boxes_array, \n",
        "                                     columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    \n",
        "    # Return the DataFrame\n",
        "    return df_bounding_boxes"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rydsMU1vLjq3"
      },
      "source": [
        "# Define all the Augmentations you want to apply to your dataset\n",
        "# We're setting random `n` agumentations to 2. \n",
        "image_augmentations = iaa.SomeOf( 2,\n",
        "    [                                 \n",
        "    # Scale the Images\n",
        "    iaa.Affine(scale=(0.5, 1.5)),\n",
        "\n",
        "    # Rotate the Images\n",
        "    iaa.Affine(rotate=(-60, 60)),\n",
        "\n",
        "    # Shift the Image\n",
        "    iaa.Affine(translate_percent={\"x\":(-0.3, 0.3),\"y\":(-0.3, 0.3)}),\n",
        "\n",
        "    # Flip the Image\n",
        "    iaa.Fliplr(1),\n",
        "\n",
        "    # Increase or decrease the brightness\n",
        "    iaa.Multiply((0.5, 1.5)),\n",
        "\n",
        "    # Add Gaussian Blur\n",
        "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
        "    \n",
        "    # Add Gaussian Noise\n",
        "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
        "\n",
        "])\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfb3bXngNk3L"
      },
      "source": [
        "def image_aug(df, images_path, aug_images_path, augmentor, multiple = 3):\n",
        "    \n",
        "    # Fill this DataFrame with image attributes\n",
        "    augmentations_df = pd.DataFrame(\n",
        "        columns=['filename','width','height','class', 'xmin', 'ymin', 'xmax',\n",
        "                 'ymax'])\n",
        "    \n",
        "    # Group the data by filenames\n",
        "    grouped_df = df.groupby('filename')\n",
        "\n",
        "    # Create the directory for all augmentated images\n",
        "    if not os.path.exists(aug_images_path):\n",
        "      os.mkdir(aug_images_path)\n",
        "\n",
        "    # Create directories for each class of augmentated images\n",
        "    for folder in df['class'].unique():\n",
        "      if not os.path.exists(os.path.join(aug_images_path, folder)):\n",
        "        os.mkdir(os.path.join(aug_images_path, folder))\n",
        "\n",
        "    for i in range(multiple):\n",
        "      \n",
        "      # Post Fix we add to the each different augmentation of one image\n",
        "      image_postfix = str(i)\n",
        "\n",
        "      # Loop to perform the augmentations\n",
        "      for filename in df['filename'].unique():\n",
        "\n",
        "        augmented_path = os.path.join(aug_images_path, filename)+image_postfix+'.jpg'\n",
        "\n",
        "        # Take one image at a time with its information\n",
        "        single_image = grouped_df.get_group(filename)\n",
        "        single_image = single_image.reset_index()\n",
        "        single_image = single_image.drop(['index'], axis=1)   \n",
        "        \n",
        "        # Read the image\n",
        "        image = imageio.imread(os.path.join(images_path, filename))\n",
        "\n",
        "        # Get bounding box\n",
        "        bounding_box_array = single_image.drop(['filename', 'width', 'height',\n",
        "                                                'class'], axis=1).values\n",
        "\n",
        "        # Give the bounding box to imgaug library\n",
        "        bounding_box = BoundingBoxesOnImage.from_xyxy_array(bounding_box_array, \n",
        "                                                            shape=image.shape)\n",
        "\n",
        "        # Perform random 2 Augmentations\n",
        "        image_aug, bounding_box_aug = augmentor(image=image, \n",
        "                                                bounding_boxes=bounding_box)\n",
        "        \n",
        "        # Discard the the bounding box going out the image completely   \n",
        "        bounding_box_aug = bounding_box_aug.remove_out_of_image()\n",
        "\n",
        "        # Clip the bounding box that are only partially out of th image\n",
        "        bounding_box_aug = bounding_box_aug.clip_out_of_image()\n",
        "\n",
        "        # Get rid of the the image if bounding box was discarded  \n",
        "        if re.findall('Image...', str(bounding_box_aug)) == ['Image([]']:\n",
        "            pass\n",
        "        \n",
        "        else:\n",
        "        \n",
        "          # Create the augmented image file\n",
        "          imageio.imwrite(augmented_path, image_aug) \n",
        "\n",
        "          # Update the image width and height after augmentation\n",
        "          info_df = single_image.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
        "          for index, _ in info_df.iterrows():\n",
        "              info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "              info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "\n",
        "          # Add the prefix to each image to differentiate if required\n",
        "          info_df['filename'] = info_df['filename'].apply(lambda x: x + image_postfix + '.jpg')\n",
        "\n",
        "          # Create the augmented bounding boxes dataframe \n",
        "          bounding_box_df = bounding_boxes_to_df(bounding_box_aug)\n",
        "\n",
        "          # Concatenate the filenames, height, width and bounding boxes \n",
        "          aug_df = pd.concat([info_df, bounding_box_df], axis=1)\n",
        "\n",
        "          # Add all the information to augmentations_df we initialized above\n",
        "          augmentations_df = pd.concat([augmentations_df, aug_df])            \n",
        "      \n",
        "    # Remove index\n",
        "    augmentations_df = augmentations_df.reset_index()\n",
        "    augmentations_df = augmentations_df.drop(['index'], axis=1)\n",
        "\n",
        "    # Return the Dataframe\n",
        "    return augmentations_df\n",
        "\n",
        "\n",
        "augmented_images_df = image_aug(labels_df, image_directory, 'aug_images', \n",
        "                                image_augmentations)"
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}